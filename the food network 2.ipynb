{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from nbutil import imshow_multi\n",
    "%matplotlib inline\n",
    "from simple import flatten, avg\n",
    "import random\n",
    "from show_graph import show_graph\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import charttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODE = 'train'\n",
    "# MODE = 'eval'\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "N_CLASSES = 102 # 101 foods + null class\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 64, 24)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 1, 1, 384)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# bias_init = tf.truncated_normal_initializer(mean=0.1, stddev=0.02)\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self, img_size, n_classes):\n",
    "        with tf.variable_scope('net'):\n",
    "            n_layers = int(math.log(img_size) / math.log(2))\n",
    "            n_layers -= 2 # skip last 2 layers; do average pooling instead\n",
    "\n",
    "            inputs = tf.placeholder(tf.float32, [None, img_size, img_size, 3], name='inputs')\n",
    "            labels = tf.placeholder(tf.int64, [None], name='labels')\n",
    "            dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "            \n",
    "            max_chans = 1024\n",
    "            initial_chans = 24\n",
    "            \n",
    "            x = self.conv(inputs, initial_chans, 1)\n",
    "            print x.get_shape()\n",
    "\n",
    "            for i, layer in enumerate(xrange(n_layers)):\n",
    "                _, h, w, _ = [d.value for d in x.get_shape()]\n",
    "                chans = min(max_chans, initial_chans * 2 ** (i+1))\n",
    "                is_training = (MODE == 'train')\n",
    "                x = self.inception_module(x, chans, 'inception-{}'.format(i))\n",
    "                x = layers.batch_norm(x, is_training=is_training, updates_collections=None)\n",
    "                x = self.inception_module(x, chans, 'inception-{}-2'.format(i))\n",
    "                x = layers.batch_norm(x, is_training=is_training, updates_collections=None)\n",
    "                \n",
    "                pooling = 2\n",
    "                if i + 1 == n_layers:\n",
    "                    pooling = h\n",
    "                x = self.pool(x, pooling, pooling, type='avg')\n",
    "                \n",
    "                if i % 2 == 0:\n",
    "                    x = tf.nn.dropout(x, dropout)\n",
    "                print x.get_shape()\n",
    "                        \n",
    "            logits = self.conv(x, n_classes, 1, activation=tf.identity)\n",
    "            logits = tf.reshape(logits, [-1, n_classes])\n",
    "\n",
    "            loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "            predictions = tf.argmax(logits, axis=-1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "\n",
    "            global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "            lr = tf.placeholder(tf.float32, name='lr')\n",
    "            train_op = tf.train.AdamOptimizer(lr).minimize(loss, global_step=global_step)\n",
    "\n",
    "            self.inputs = inputs\n",
    "            self.labels = labels\n",
    "            self.loss = loss\n",
    "            self.logits = logits\n",
    "            self.predictions = predictions\n",
    "            self.accuracy = accuracy\n",
    "            self.global_step = global_step\n",
    "            self.train_op = train_op\n",
    "            self.lr = lr\n",
    "            self.dropout = dropout\n",
    "    \n",
    "    def conv(self, x, channels, ksize, activation=tf.nn.elu):\n",
    "        return layers.conv2d(x, \n",
    "                             channels,\n",
    "                             kernel_size=ksize, \n",
    "                             activation_fn=activation)\n",
    "    \n",
    "    def pool(self, x, ksize, stride, type='max'):\n",
    "        fn = {'max': tf.nn.max_pool, 'avg': tf.nn.avg_pool}[type]\n",
    "        return fn(x, [1, ksize, ksize, 1], [1, stride, stride, 1], 'SAME')\n",
    "    \n",
    "    def inception_module(self, x, out_channels, name):\n",
    "        # https://culurciello.github.io/tech/2016/06/04/nets.html\n",
    "        # out_channels channels must be a multiple of 4\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            channels = x.get_shape()[-1].value\n",
    "            bsize = out_channels / 4\n",
    "            \n",
    "            y1 = self.conv(x, bsize, 1)\n",
    "            y2 = self.conv(self.pool(x, 3, 1, 'avg'), bsize, 1)\n",
    "            y3 = self.conv(self.conv(x, bsize, 1), bsize, 3)\n",
    "            y4 = self.conv(self.conv(self.conv(x, bsize, 1), bsize, 3), bsize, 3)\n",
    "            \n",
    "            return tf.concat([y1, y2, y3, y4], axis=-1)\n",
    "\n",
    "n = Net(IMAGE_SIZE, N_CLASSES)\n",
    "print 'ok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception module v3 \n",
    "\n",
    "<img src='https://culurciello.github.io/assets/nets/inceptionv3.jpg' width=300 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'null', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n"
     ]
    }
   ],
   "source": [
    "root = '../data/food-101/images'\n",
    "labels = sorted(os.listdir(root))\n",
    "\n",
    "paths_to_labels = {}\n",
    "\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(root, label)\n",
    "    for name in os.listdir(label_dir):\n",
    "        if name.endswith('.jpg') or name.endswith('.png') or name.endswith('.gif'):\n",
    "            path = os.path.join(label_dir, name)\n",
    "            paths_to_labels[path] = label\n",
    "\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_image_queue(filenames, batch_size=BATCH_SIZE, grayscale=False, size=128):\n",
    "    filename_tensor = tf.convert_to_tensor(filenames, dtype=tf.string)\n",
    "    filename_q = tf.train.slice_input_producer([filename_tensor], num_epochs=None, shuffle=True)[0]\n",
    "\n",
    "    image_255 = tf.image.decode_jpeg(tf.read_file(filename_q), channels=3)\n",
    "    image = tf.cast(image_255, tf.float32) / 255.0\n",
    "    if grayscale:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    \n",
    "    def resize_image(image):\n",
    "        pre_crop_size = tf.cast(size + tf.random_uniform([]) * size * 0.3, tf.int32)\n",
    "        image_as_batch_of_1 = tf.expand_dims(image, 0)\n",
    "        image = tf.image.resize_bilinear(image_as_batch_of_1, [pre_crop_size, pre_crop_size])[0]\n",
    "        image = tf.random_crop(image, [size, size, 3])\n",
    "        return image\n",
    "    \n",
    "    image = resize_image(image)\n",
    "\n",
    "    def distort_image(image):\n",
    "        # noise_amt = tf.abs(tf.random_normal([], stddev=0.2))\n",
    "        # distorted_image = image + tf.random_uniform([299, 299, 3], maxval=noise_amt)\n",
    "        distorted_image = tf.image.random_flip_left_right(image)\n",
    "        distorted_image = tf.image.random_brightness(distorted_image, max_delta=0.15)\n",
    "        distorted_image = tf.image.random_contrast(distorted_image, lower=0.8, upper=1.2)\n",
    "        return distorted_image\n",
    "    \n",
    "    image = distort_image(image)\n",
    "    \n",
    "    images_batch, filenames_batch = tf.train.shuffle_batch([image, filename_q], batch_size=batch_size, capacity=128, min_after_dequeue=64)\n",
    "    return images_batch, filenames_batch\n",
    "\n",
    "images_batch, filenames_batch = create_image_queue(paths_to_labels.keys(), size=IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# images_batch, filenames_batch = create_image_queue(paths_to_labels.keys(), size=IMAGE_SIZE)\n",
    "\n",
    "# init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "# sess.run(init_op)\n",
    "# tf.train.start_queue_runners(sess=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images, filenames = sess.run([images_batch, filenames_batch])\n",
    "# imshow_multi(list(images)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:net/global_step/sec: 0\n",
      "34736: loss=40.7900648753, acc=0.341666666667, epoch=5.50273267327\n",
      "34752: loss=42.2638454437, acc=0.34375, epoch=5.50526732673\n",
      "34768: loss=44.0864868164, acc=0.31640625, epoch=5.5078019802\n",
      "34784: loss=44.1997890472, acc=0.38671875, epoch=5.51033663366\n",
      "34800: loss=47.5480903387, acc=0.28125, epoch=5.51287128713\n",
      "34816: loss=45.5028550625, acc=0.328125, epoch=5.51540594059\n",
      "34832: loss=44.0713536739, acc=0.37890625, epoch=5.51794059406\n",
      "34848: loss=46.0212504864, acc=0.33203125, epoch=5.52047524752\n",
      "34864: loss=41.6136844158, acc=0.34765625, epoch=5.52300990099\n",
      "34880: loss=42.7581777573, acc=0.33203125, epoch=5.52554455446\n",
      "34896: loss=42.1631726027, acc=0.34375, epoch=5.52807920792\n",
      "34912: loss=43.2914100885, acc=0.33984375, epoch=5.53061386139\n",
      "34928: loss=42.9834604263, acc=0.33984375, epoch=5.53314851485\n",
      "34944: loss=44.6785809994, acc=0.3203125, epoch=5.53568316832\n",
      "34960: loss=42.8449320793, acc=0.3828125, epoch=5.53821782178\n",
      "34976: loss=45.4202480316, acc=0.30078125, epoch=5.54075247525\n",
      "34992: loss=44.2988314629, acc=0.296875, epoch=5.54328712871\n",
      "35008: loss=44.227217555, acc=0.3046875, epoch=5.54582178218\n",
      "35024: loss=40.9446827173, acc=0.3515625, epoch=5.54835643564\n",
      "35040: loss=46.6100389957, acc=0.27734375, epoch=5.55089108911\n",
      "35056: loss=41.7153379917, acc=0.33984375, epoch=5.55342574257\n",
      "35072: loss=43.7379624844, acc=0.31640625, epoch=5.55596039604\n",
      "35088: loss=42.1580268145, acc=0.3671875, epoch=5.5584950495\n",
      "35104: loss=45.3906424046, acc=0.3203125, epoch=5.56102970297\n",
      "35120: loss=44.583104372, acc=0.328125, epoch=5.56356435644\n",
      "35136: loss=42.0898844004, acc=0.3515625, epoch=5.5660990099\n",
      "35152: loss=42.010361433, acc=0.35546875, epoch=5.56863366337\n",
      "35168: loss=41.1314835548, acc=0.34375, epoch=5.57116831683\n",
      "35184: loss=46.6182299852, acc=0.3046875, epoch=5.5737029703\n",
      "35200: loss=44.9889163971, acc=0.31640625, epoch=5.57623762376\n",
      "35216: loss=44.5615501404, acc=0.3125, epoch=5.57877227723\n",
      "35232: loss=43.3535557985, acc=0.3125, epoch=5.58130693069\n",
      "35248: loss=42.7048187256, acc=0.33203125, epoch=5.58384158416\n",
      "35264: loss=41.2905948162, acc=0.35546875, epoch=5.58637623762\n",
      "35280: loss=44.7014968395, acc=0.30078125, epoch=5.58891089109\n",
      "35296: loss=44.330463171, acc=0.3359375, epoch=5.59144554455\n",
      "INFO:tensorflow:net/global_step/sec: 4.90078\n",
      "35312: loss=46.0033445358, acc=0.31640625, epoch=5.59398019802\n",
      "35328: loss=40.3426017761, acc=0.3671875, epoch=5.59651485149\n",
      "35344: loss=40.4115759134, acc=0.39453125, epoch=5.59904950495\n",
      "35360: loss=44.9001684189, acc=0.3203125, epoch=5.60158415842\n",
      "35376: loss=43.5321394205, acc=0.33203125, epoch=5.60411881188\n",
      "35392: loss=42.7540006638, acc=0.359375, epoch=5.60665346535\n",
      "35408: loss=41.5815351009, acc=0.35546875, epoch=5.60918811881\n",
      "35424: loss=42.4065705538, acc=0.36328125, epoch=5.61172277228\n",
      "35440: loss=41.555198431, acc=0.3671875, epoch=5.61425742574\n",
      "35456: loss=41.4278559685, acc=0.37109375, epoch=5.61679207921\n",
      "35472: loss=41.92263484, acc=0.3671875, epoch=5.61932673267\n",
      "35488: loss=42.1917045116, acc=0.34765625, epoch=5.62186138614\n",
      "35504: loss=46.1900632381, acc=0.296875, epoch=5.6243960396\n",
      "35520: loss=44.2776124477, acc=0.31640625, epoch=5.62693069307\n",
      "35536: loss=43.8345980644, acc=0.35546875, epoch=5.62946534653\n",
      "35552: loss=44.7176148891, acc=0.33984375, epoch=5.632\n",
      "35568: loss=43.6322159767, acc=0.328125, epoch=5.63453465347\n",
      "35584: loss=43.8866696358, acc=0.3359375, epoch=5.63706930693\n",
      "35600: loss=42.1347141266, acc=0.3359375, epoch=5.6396039604\n",
      "35616: loss=42.4584459066, acc=0.37890625, epoch=5.64213861386\n",
      "35632: loss=40.7456424236, acc=0.375, epoch=5.64467326733\n",
      "35648: loss=42.8790643215, acc=0.34375, epoch=5.64720792079\n",
      "35664: loss=41.366429925, acc=0.37109375, epoch=5.64974257426\n",
      "35680: loss=42.0738338232, acc=0.359375, epoch=5.65227722772\n",
      "35696: loss=43.8727500439, acc=0.33203125, epoch=5.65481188119\n",
      "35712: loss=40.3553309441, acc=0.39453125, epoch=5.65734653465\n",
      "35728: loss=44.0776391029, acc=0.32421875, epoch=5.65988118812\n",
      "35744: loss=43.7477834225, acc=0.2890625, epoch=5.66241584158\n",
      "35760: loss=46.4594762325, acc=0.30859375, epoch=5.66495049505\n",
      "35776: loss=42.2116804123, acc=0.35546875, epoch=5.66748514851\n",
      "35792: loss=44.5256850719, acc=0.32421875, epoch=5.67001980198\n",
      "35808: loss=41.6121499538, acc=0.37109375, epoch=5.67255445545\n",
      "35824: loss=43.5724577904, acc=0.33203125, epoch=5.67508910891\n",
      "35840: loss=43.878888011, acc=0.30078125, epoch=5.67762376238\n",
      "35856: loss=43.2381668091, acc=0.37109375, epoch=5.68015841584\n",
      "35872: loss=41.4344421625, acc=0.3515625, epoch=5.68269306931\n",
      "35888: loss=44.0595910549, acc=0.34375, epoch=5.68522772277\n",
      "35904: loss=43.4341026545, acc=0.31640625, epoch=5.68776237624\n",
      "INFO:tensorflow:net/global_step/sec: 5.06667\n",
      "35920: loss=43.2679624557, acc=0.359375, epoch=5.6902970297\n",
      "35936: loss=45.6912202835, acc=0.28125, epoch=5.69283168317\n",
      "35952: loss=42.9257752895, acc=0.34375, epoch=5.69536633663\n",
      "35968: loss=44.5530107021, acc=0.3359375, epoch=5.6979009901\n",
      "35984: loss=44.7862913609, acc=0.296875, epoch=5.70043564356\n",
      "36000: loss=44.1535887718, acc=0.3359375, epoch=5.70297029703\n",
      "36016: loss=42.1929571629, acc=0.37890625, epoch=5.7055049505\n",
      "36032: loss=38.5698698759, acc=0.41015625, epoch=5.70803960396\n",
      "36048: loss=42.2662711143, acc=0.33984375, epoch=5.71057425743\n",
      "36064: loss=43.751210928, acc=0.33203125, epoch=5.71310891089\n",
      "36080: loss=43.1295809746, acc=0.3515625, epoch=5.71564356436\n",
      "36096: loss=43.3659720421, acc=0.34765625, epoch=5.71817821782\n",
      "36112: loss=44.9497840405, acc=0.3125, epoch=5.72071287129\n",
      "36128: loss=44.4001507759, acc=0.34375, epoch=5.72324752475\n",
      "36144: loss=42.1967951059, acc=0.37109375, epoch=5.72578217822\n",
      "36160: loss=44.2899026871, acc=0.3359375, epoch=5.72831683168\n",
      "36176: loss=45.9989864826, acc=0.3046875, epoch=5.73085148515\n",
      "36192: loss=43.4943441153, acc=0.3359375, epoch=5.73338613861\n",
      "36208: loss=41.4761841297, acc=0.3203125, epoch=5.73592079208\n",
      "36224: loss=44.5191715956, acc=0.36328125, epoch=5.73845544554\n",
      "36240: loss=40.2045035362, acc=0.4140625, epoch=5.74099009901\n",
      "36256: loss=44.913179636, acc=0.36328125, epoch=5.74352475248\n",
      "36272: loss=43.6817080975, acc=0.3515625, epoch=5.74605940594\n",
      "36288: loss=44.5566949844, acc=0.3203125, epoch=5.74859405941\n",
      "36304: loss=39.5130567551, acc=0.3828125, epoch=5.75112871287\n",
      "36320: loss=41.9409611225, acc=0.34375, epoch=5.75366336634\n",
      "36336: loss=40.6748268604, acc=0.359375, epoch=5.7561980198\n",
      "36352: loss=43.7147212029, acc=0.3359375, epoch=5.75873267327\n",
      "36368: loss=44.8128242493, acc=0.3359375, epoch=5.76126732673\n",
      "36384: loss=44.4123895168, acc=0.31640625, epoch=5.7638019802\n",
      "36400: loss=44.490524292, acc=0.33203125, epoch=5.76633663366\n",
      "36416: loss=43.2360560894, acc=0.33203125, epoch=5.76887128713\n",
      "36432: loss=45.2473413944, acc=0.31640625, epoch=5.77140594059\n",
      "36448: loss=44.0429992676, acc=0.328125, epoch=5.77394059406\n",
      "36464: loss=40.6983168125, acc=0.34375, epoch=5.77647524752\n",
      "36480: loss=41.8959829807, acc=0.328125, epoch=5.77900990099\n",
      "36496: loss=41.12581563, acc=0.390625, epoch=5.78154455446\n",
      "36512: loss=41.7478034496, acc=0.34765625, epoch=5.78407920792\n",
      "INFO:tensorflow:net/global_step/sec: 4.98333\n",
      "36528: loss=44.6179869175, acc=0.3203125, epoch=5.78661386139\n",
      "36544: loss=41.1469368935, acc=0.375, epoch=5.78914851485\n",
      "36560: loss=43.5356128216, acc=0.328125, epoch=5.79168316832\n",
      "36576: loss=38.4976768494, acc=0.39453125, epoch=5.79421782178\n",
      "36592: loss=46.3455228806, acc=0.33984375, epoch=5.79675247525\n",
      "36608: loss=39.0842690468, acc=0.40625, epoch=5.79928712871\n",
      "36624: loss=39.8215651512, acc=0.375, epoch=5.80182178218\n",
      "36640: loss=44.2681891918, acc=0.31640625, epoch=5.80435643564\n",
      "36656: loss=42.894724369, acc=0.3671875, epoch=5.80689108911\n",
      "36672: loss=42.38346982, acc=0.359375, epoch=5.80942574257\n",
      "36688: loss=42.7211229801, acc=0.37109375, epoch=5.81196039604\n",
      "36704: loss=42.4204797745, acc=0.3671875, epoch=5.8144950495\n",
      "36720: loss=43.6762968302, acc=0.34765625, epoch=5.81702970297\n",
      "36736: loss=43.8340697289, acc=0.33984375, epoch=5.81956435644\n",
      "36752: loss=45.5821174383, acc=0.34375, epoch=5.8220990099\n",
      "36768: loss=40.9868540764, acc=0.35546875, epoch=5.82463366337\n",
      "36784: loss=43.2496168613, acc=0.33203125, epoch=5.82716831683\n",
      "36800: loss=44.8808858395, acc=0.3125, epoch=5.8297029703\n",
      "36816: loss=42.3994247913, acc=0.3203125, epoch=5.83223762376\n",
      "36832: loss=44.392875433, acc=0.31640625, epoch=5.83477227723\n",
      "36848: loss=41.8928471804, acc=0.3828125, epoch=5.83730693069\n",
      "36864: loss=45.3242321014, acc=0.2890625, epoch=5.83984158416\n",
      "36880: loss=42.6051151752, acc=0.3203125, epoch=5.84237623762\n",
      "36896: loss=46.9116842747, acc=0.3125, epoch=5.84491089109\n",
      "36912: loss=43.6516711712, acc=0.34375, epoch=5.84744554455\n",
      "36928: loss=41.0302724838, acc=0.34765625, epoch=5.84998019802\n",
      "36944: loss=44.3525993824, acc=0.3203125, epoch=5.85251485149\n",
      "36960: loss=42.5016545057, acc=0.36328125, epoch=5.85504950495\n",
      "36976: loss=43.3728730679, acc=0.34765625, epoch=5.85758415842\n",
      "36992: loss=44.1303515434, acc=0.30859375, epoch=5.86011881188\n",
      "37008: loss=45.813069582, acc=0.30859375, epoch=5.86265346535\n",
      "37024: loss=41.1226557493, acc=0.38671875, epoch=5.86518811881\n",
      "37040: loss=41.0784837008, acc=0.390625, epoch=5.86772277228\n",
      "37056: loss=44.0678637028, acc=0.36328125, epoch=5.87025742574\n",
      "37072: loss=44.0418255329, acc=0.33984375, epoch=5.87279207921\n",
      "37088: loss=47.4322621822, acc=0.3203125, epoch=5.87532673267\n",
      "37104: loss=44.0576021671, acc=0.33984375, epoch=5.87786138614\n",
      "INFO:tensorflow:net/global_step/sec: 5\n",
      "37120: loss=43.4828344584, acc=0.3359375, epoch=5.8803960396\n",
      "37136: loss=41.5439872742, acc=0.33203125, epoch=5.88293069307\n",
      "37152: loss=43.66429317, acc=0.3125, epoch=5.88546534653\n",
      "37168: loss=42.4165923595, acc=0.32421875, epoch=5.888\n",
      "37184: loss=43.8064732552, acc=0.3515625, epoch=5.89053465347\n",
      "37200: loss=43.7025966644, acc=0.3515625, epoch=5.89306930693\n",
      "37216: loss=42.5295956135, acc=0.3515625, epoch=5.8956039604\n",
      "37232: loss=45.7195651531, acc=0.28515625, epoch=5.89813861386\n",
      "37248: loss=42.6872594357, acc=0.35546875, epoch=5.90067326733\n",
      "37264: loss=42.6377754211, acc=0.3515625, epoch=5.90320792079\n",
      "37280: loss=41.9300158024, acc=0.37890625, epoch=5.90574257426\n",
      "37296: loss=40.2665094137, acc=0.40625, epoch=5.90827722772\n",
      "37312: loss=44.5006184578, acc=0.3203125, epoch=5.91081188119\n",
      "37328: loss=41.4397866726, acc=0.38671875, epoch=5.91334653465\n",
      "37344: loss=42.7993607521, acc=0.375, epoch=5.91588118812\n",
      "37360: loss=41.8352937698, acc=0.3828125, epoch=5.91841584158\n",
      "37376: loss=42.3130187988, acc=0.35546875, epoch=5.92095049505\n",
      "37392: loss=43.6861770153, acc=0.3359375, epoch=5.92348514851\n",
      "37408: loss=39.7167485952, acc=0.38671875, epoch=5.92601980198\n",
      "37424: loss=43.3943111897, acc=0.32421875, epoch=5.92855445545\n",
      "37440: loss=39.7159019709, acc=0.37109375, epoch=5.93108910891\n",
      "37456: loss=44.9372532368, acc=0.3125, epoch=5.93362376238\n",
      "37472: loss=38.5843948126, acc=0.390625, epoch=5.93615841584\n",
      "37488: loss=41.5844153166, acc=0.35546875, epoch=5.93869306931\n",
      "37504: loss=43.551251173, acc=0.30078125, epoch=5.94122772277\n",
      "37520: loss=42.3729498386, acc=0.3515625, epoch=5.94376237624\n",
      "37536: loss=42.5503528118, acc=0.33203125, epoch=5.9462970297\n",
      "37552: loss=45.3485982418, acc=0.36328125, epoch=5.94883168317\n",
      "37568: loss=42.3205177784, acc=0.3359375, epoch=5.95136633663\n",
      "37584: loss=43.0140012503, acc=0.33203125, epoch=5.9539009901\n",
      "37600: loss=43.62532866, acc=0.33203125, epoch=5.95643564356\n",
      "37616: loss=43.7939395905, acc=0.33984375, epoch=5.95897029703\n",
      "37632: loss=41.6051031351, acc=0.36328125, epoch=5.9615049505\n",
      "37648: loss=41.9448099136, acc=0.3515625, epoch=5.96403960396\n",
      "37664: loss=43.2887508869, acc=0.3359375, epoch=5.96657425743\n",
      "37680: loss=41.7370393276, acc=0.38671875, epoch=5.96910891089\n",
      "37696: loss=41.4413518906, acc=0.375, epoch=5.97164356436\n",
      "37712: loss=41.8850566149, acc=0.375, epoch=5.97417821782\n",
      "INFO:tensorflow:net/global_step/sec: 4.975\n",
      "37728: loss=46.7609820366, acc=0.27734375, epoch=5.97671287129\n",
      "37744: loss=38.8550878763, acc=0.37109375, epoch=5.97924752475\n",
      "37760: loss=43.3135108948, acc=0.375, epoch=5.98178217822\n",
      "37776: loss=46.6077005863, acc=0.30859375, epoch=5.98431683168\n",
      "37792: loss=43.0609540939, acc=0.36328125, epoch=5.98685148515\n",
      "37808: loss=41.7988696098, acc=0.375, epoch=5.98938613861\n",
      "37824: loss=43.5423203707, acc=0.31640625, epoch=5.99192079208\n",
      "37840: loss=40.4032491446, acc=0.359375, epoch=5.99445544554\n",
      "37856: loss=45.0427422523, acc=0.328125, epoch=5.99699009901\n",
      "37872: loss=40.0785601139, acc=0.3515625, epoch=5.99952475248\n",
      "37888: loss=41.7132425308, acc=0.375, epoch=6.00205940594\n",
      "37904: loss=42.3924984932, acc=0.3671875, epoch=6.00459405941\n",
      "37920: loss=41.654746294, acc=0.34375, epoch=6.00712871287\n",
      "37936: loss=44.1690740585, acc=0.35546875, epoch=6.00966336634\n",
      "37952: loss=42.1275981665, acc=0.33984375, epoch=6.0121980198\n",
      "37968: loss=38.8840641975, acc=0.4296875, epoch=6.01473267327\n",
      "37984: loss=41.6117486954, acc=0.35546875, epoch=6.01726732673\n",
      "38000: loss=42.7761604786, acc=0.31640625, epoch=6.0198019802\n",
      "38016: loss=41.4809764624, acc=0.35546875, epoch=6.02233663366\n",
      "38032: loss=43.4553545713, acc=0.32421875, epoch=6.02487128713\n",
      "38048: loss=41.0558822155, acc=0.3515625, epoch=6.02740594059\n",
      "38064: loss=45.3441915512, acc=0.3046875, epoch=6.02994059406\n",
      "38080: loss=42.55509305, acc=0.34375, epoch=6.03247524752\n",
      "38096: loss=41.8886370659, acc=0.35546875, epoch=6.03500990099\n",
      "38112: loss=43.5611517429, acc=0.37890625, epoch=6.03754455446\n",
      "38128: loss=44.8848574162, acc=0.34765625, epoch=6.04007920792\n",
      "38144: loss=43.8568928242, acc=0.3203125, epoch=6.04261386139\n",
      "38160: loss=44.7262406349, acc=0.3046875, epoch=6.04514851485\n",
      "38176: loss=42.9481911659, acc=0.3515625, epoch=6.04768316832\n",
      "38192: loss=42.9003529549, acc=0.34375, epoch=6.05021782178\n",
      "38208: loss=40.7679321766, acc=0.37890625, epoch=6.05275247525\n",
      "38224: loss=40.0749680996, acc=0.38671875, epoch=6.05528712871\n",
      "38240: loss=44.8189713955, acc=0.29296875, epoch=6.05782178218\n",
      "38256: loss=43.8806955814, acc=0.3125, epoch=6.06035643564\n",
      "38272: loss=43.7497041225, acc=0.3515625, epoch=6.06289108911\n",
      "38288: loss=42.8519015312, acc=0.3671875, epoch=6.06542574257\n",
      "38304: loss=42.1733506918, acc=0.34375, epoch=6.06796039604\n",
      "INFO:tensorflow:net/global_step/sec: 4.99167\n",
      "38320: loss=45.8880867958, acc=0.296875, epoch=6.0704950495\n",
      "38336: loss=43.3826389313, acc=0.34375, epoch=6.07302970297\n",
      "38352: loss=42.7908574343, acc=0.33984375, epoch=6.07556435644\n",
      "38368: loss=43.3149341345, acc=0.34765625, epoch=6.0780990099\n",
      "38384: loss=40.6875625849, acc=0.37109375, epoch=6.08063366337\n",
      "38400: loss=44.9928417206, acc=0.30859375, epoch=6.08316831683\n",
      "38416: loss=45.3881442547, acc=0.3203125, epoch=6.0857029703\n",
      "38432: loss=39.4001179934, acc=0.3984375, epoch=6.08823762376\n",
      "38448: loss=45.4574313164, acc=0.30859375, epoch=6.09077227723\n",
      "38464: loss=43.4211499691, acc=0.296875, epoch=6.09330693069\n",
      "38480: loss=42.6281967163, acc=0.328125, epoch=6.09584158416\n",
      "38496: loss=44.3809062243, acc=0.3359375, epoch=6.09837623762\n",
      "38512: loss=42.766351819, acc=0.3359375, epoch=6.10091089109\n",
      "38528: loss=43.6129477024, acc=0.34375, epoch=6.10344554455\n",
      "38544: loss=40.2976015806, acc=0.3359375, epoch=6.10598019802\n",
      "38560: loss=44.2138388157, acc=0.34765625, epoch=6.10851485149\n",
      "38576: loss=43.0523538589, acc=0.35546875, epoch=6.11104950495\n",
      "38592: loss=44.5904679298, acc=0.34765625, epoch=6.11358415842\n",
      "38608: loss=44.897701025, acc=0.3046875, epoch=6.11611881188\n",
      "38624: loss=41.5777304173, acc=0.40625, epoch=6.11865346535\n",
      "38640: loss=46.7943279743, acc=0.33203125, epoch=6.12118811881\n",
      "39792: loss=39.9468041658, acc=0.3671875, epoch=6.30368316832\n",
      "39808: loss=42.1498780251, acc=0.3984375, epoch=6.30621782178\n",
      "39824: loss=43.4211080074, acc=0.35546875, epoch=6.30875247525\n",
      "39840: loss=45.6678988934, acc=0.31640625, epoch=6.31128712871\n",
      "39856: loss=43.5587278605, acc=0.375, epoch=6.31382178218\n",
      "39872: loss=40.4929361343, acc=0.40625, epoch=6.31635643564\n",
      "39888: loss=42.5893220901, acc=0.34375, epoch=6.31889108911\n",
      "39904: loss=42.4405910969, acc=0.35546875, epoch=6.32142574257\n",
      "39920: loss=41.8284494877, acc=0.359375, epoch=6.32396039604\n",
      "39936: loss=41.2958316803, acc=0.32421875, epoch=6.3264950495\n",
      "39952: loss=39.6084578037, acc=0.375, epoch=6.32902970297\n",
      "39968: loss=42.4516968727, acc=0.32421875, epoch=6.33156435644\n",
      "39984: loss=43.1911854744, acc=0.34765625, epoch=6.3340990099\n",
      "40000: loss=40.7453427315, acc=0.35546875, epoch=6.33663366337\n",
      "40016: loss=41.9420998096, acc=0.34765625, epoch=6.33916831683\n",
      "40032: loss=44.2235994339, acc=0.35546875, epoch=6.3417029703\n",
      "40048: loss=43.1870900393, acc=0.3125, epoch=6.34423762376\n",
      "40064: loss=43.9684083462, acc=0.3515625, epoch=6.34677227723\n",
      "40080: loss=42.673987627, acc=0.3359375, epoch=6.34930693069\n",
      "40096: loss=41.8401556015, acc=0.359375, epoch=6.35184158416\n",
      "INFO:tensorflow:net/global_step/sec: 5.03333\n",
      "40112: loss=43.8495202065, acc=0.375, epoch=6.35437623762\n",
      "40128: loss=45.4039838314, acc=0.3203125, epoch=6.35691089109\n",
      "40144: loss=43.0781648159, acc=0.359375, epoch=6.35944554455\n",
      "40160: loss=40.602353096, acc=0.3671875, epoch=6.36198019802\n",
      "40176: loss=42.9096570015, acc=0.359375, epoch=6.36451485149\n",
      "40192: loss=41.4805659056, acc=0.390625, epoch=6.36704950495\n",
      "40208: loss=41.7683250904, acc=0.328125, epoch=6.36958415842\n",
      "40224: loss=40.1317623854, acc=0.34765625, epoch=6.37211881188\n",
      "40240: loss=41.8716250658, acc=0.36328125, epoch=6.37465346535\n",
      "40256: loss=41.7501261234, acc=0.33984375, epoch=6.37718811881\n",
      "40272: loss=41.8168716431, acc=0.359375, epoch=6.37972277228\n",
      "40288: loss=42.9431142807, acc=0.35546875, epoch=6.38225742574\n",
      "40304: loss=44.0193231106, acc=0.3359375, epoch=6.38479207921\n",
      "40320: loss=42.3192214966, acc=0.3671875, epoch=6.38732673267\n",
      "40336: loss=42.7315533161, acc=0.39453125, epoch=6.38986138614\n",
      "40352: loss=41.7033298016, acc=0.34765625, epoch=6.3923960396\n",
      "40368: loss=44.6182162762, acc=0.37109375, epoch=6.39493069307\n",
      "40384: loss=41.7761473656, acc=0.37890625, epoch=6.39746534653\n",
      "40400: loss=43.6705367565, acc=0.31640625, epoch=6.4\n",
      "40416: loss=43.1296956539, acc=0.328125, epoch=6.40253465347\n",
      "40432: loss=42.240801096, acc=0.37109375, epoch=6.40506930693\n",
      "40448: loss=42.4945936203, acc=0.35546875, epoch=6.4076039604\n",
      "40464: loss=42.7731480598, acc=0.37109375, epoch=6.41013861386\n",
      "40480: loss=41.5494861603, acc=0.375, epoch=6.41267326733\n",
      "40496: loss=43.7373154163, acc=0.328125, epoch=6.41520792079\n",
      "40512: loss=39.5121498108, acc=0.3984375, epoch=6.41774257426\n",
      "40528: loss=46.0677645206, acc=0.30859375, epoch=6.42027722772\n",
      "40544: loss=39.7046751976, acc=0.40625, epoch=6.42281188119\n",
      "40560: loss=44.5100053549, acc=0.30078125, epoch=6.42534653465\n",
      "40576: loss=44.2853672504, acc=0.3515625, epoch=6.42788118812\n",
      "40592: loss=43.9228672981, acc=0.3515625, epoch=6.43041584158\n",
      "40608: loss=44.521017313, acc=0.33984375, epoch=6.43295049505\n",
      "40624: loss=39.2159759998, acc=0.41796875, epoch=6.43548514851\n",
      "40640: loss=46.8740200996, acc=0.3046875, epoch=6.43801980198\n",
      "40656: loss=42.4855885506, acc=0.359375, epoch=6.44055445545\n",
      "40672: loss=42.9573260546, acc=0.359375, epoch=6.44308910891\n",
      "40688: loss=43.1268422604, acc=0.39453125, epoch=6.44562376238\n",
      "40704: loss=42.4845772982, acc=0.359375, epoch=6.44815841584\n",
      "40720: loss=42.0626837015, acc=0.3515625, epoch=6.45069306931\n",
      "40736: loss=40.4223928452, acc=0.3984375, epoch=6.45322772277\n",
      "40752: loss=41.368363142, acc=0.37109375, epoch=6.45576237624\n",
      "40768: loss=39.7220731974, acc=0.37890625, epoch=6.4582970297\n",
      "40784: loss=41.3753848076, acc=0.35546875, epoch=6.46083168317\n",
      "40800: loss=44.3701509237, acc=0.34765625, epoch=6.46336633663\n",
      "40816: loss=41.0615215302, acc=0.37109375, epoch=6.4659009901\n",
      "40832: loss=45.3869037628, acc=0.33203125, epoch=6.46843564356\n",
      "40848: loss=40.6116752625, acc=0.3984375, epoch=6.47097029703\n",
      "40864: loss=40.0419585705, acc=0.42578125, epoch=6.4735049505\n",
      "40880: loss=40.6143149137, acc=0.37109375, epoch=6.47603960396\n",
      "40896: loss=41.0984627008, acc=0.3359375, epoch=6.47857425743\n",
      "40912: loss=41.2404302359, acc=0.3671875, epoch=6.48110891089\n",
      "40928: loss=40.2867472172, acc=0.37109375, epoch=6.48364356436\n",
      "40944: loss=38.2360193729, acc=0.453125, epoch=6.48617821782\n",
      "40960: loss=40.1049306393, acc=0.37890625, epoch=6.48871287129\n",
      "40976: loss=42.6625037193, acc=0.35546875, epoch=6.49124752475\n",
      "40992: loss=42.8306949139, acc=0.33984375, epoch=6.49378217822\n",
      "41008: loss=44.4570481777, acc=0.30859375, epoch=6.49631683168\n",
      "41024: loss=44.5133733749, acc=0.34765625, epoch=6.49885148515\n",
      "41040: loss=39.4577559233, acc=0.39453125, epoch=6.50138613861\n",
      "41056: loss=40.2262547016, acc=0.41015625, epoch=6.50392079208\n",
      "41072: loss=42.0580434799, acc=0.36328125, epoch=6.50645544554\n",
      "41088: loss=40.1940119267, acc=0.34765625, epoch=6.50899009901\n",
      "41104: loss=44.0853714943, acc=0.32421875, epoch=6.51152475248\n",
      "41120: loss=40.4671547413, acc=0.43359375, epoch=6.51405940594\n",
      "41136: loss=41.0082409382, acc=0.3671875, epoch=6.51659405941\n",
      "41152: loss=42.7801599503, acc=0.34765625, epoch=6.51912871287\n",
      "41168: loss=40.6671178341, acc=0.328125, epoch=6.52166336634\n",
      "41184: loss=41.5482635498, acc=0.37890625, epoch=6.5241980198\n",
      "41200: loss=42.5515482426, acc=0.3359375, epoch=6.52673267327\n",
      "41216: loss=41.1230697632, acc=0.359375, epoch=6.52926732673\n",
      "41232: loss=44.6289465427, acc=0.31640625, epoch=6.5318019802\n",
      "41248: loss=40.306278944, acc=0.359375, epoch=6.53433663366\n",
      "41264: loss=39.9083763361, acc=0.3515625, epoch=6.53687128713\n",
      "41280: loss=45.4547493458, acc=0.296875, epoch=6.53940594059\n",
      "41296: loss=44.8082034588, acc=0.28125, epoch=6.54194059406\n",
      "41312: loss=45.3029631376, acc=0.30859375, epoch=6.54447524752\n",
      "41328: loss=38.5918161869, acc=0.41796875, epoch=6.54700990099\n",
      "41344: loss=42.4185725451, acc=0.3828125, epoch=6.54954455446\n",
      "41360: loss=40.450974822, acc=0.36328125, epoch=6.55207920792\n",
      "41376: loss=41.2881321907, acc=0.3671875, epoch=6.55461386139\n",
      "41392: loss=43.3751430511, acc=0.34765625, epoch=6.55714851485\n",
      "41408: loss=41.4694724083, acc=0.3515625, epoch=6.55968316832\n",
      "41424: loss=41.5356199741, acc=0.32421875, epoch=6.56221782178\n",
      "41440: loss=41.5465596914, acc=0.36328125, epoch=6.56475247525\n",
      "41456: loss=41.1230660677, acc=0.39453125, epoch=6.56728712871\n",
      "41472: loss=43.5238318443, acc=0.3359375, epoch=6.56982178218\n",
      "41488: loss=39.6059179306, acc=0.39453125, epoch=6.57235643564\n",
      "41504: loss=39.4651004076, acc=0.39453125, epoch=6.57489108911\n",
      "41520: loss=45.5422314405, acc=0.33203125, epoch=6.57742574257\n",
      "41536: loss=42.0838696957, acc=0.33984375, epoch=6.57996039604\n",
      "41552: loss=41.6959831715, acc=0.33203125, epoch=6.5824950495\n",
      "41568: loss=40.3690609932, acc=0.3984375, epoch=6.58502970297\n",
      "41584: loss=44.1073551178, acc=0.33203125, epoch=6.58756435644\n",
      "41600: loss=38.7257957458, acc=0.37890625, epoch=6.5900990099\n",
      "41616: loss=42.1949948072, acc=0.375, epoch=6.59263366337\n",
      "41632: loss=44.5319738388, acc=0.33203125, epoch=6.59516831683\n",
      "41648: loss=44.1958720684, acc=0.328125, epoch=6.5977029703\n",
      "41664: loss=42.3884034157, acc=0.3515625, epoch=6.60023762376\n",
      "41680: loss=43.0177886486, acc=0.359375, epoch=6.60277227723\n",
      "41696: loss=42.2964003086, acc=0.359375, epoch=6.60530693069\n",
      "41712: loss=40.2518975735, acc=0.359375, epoch=6.60784158416\n",
      "41728: loss=42.2215121984, acc=0.3515625, epoch=6.61037623762\n",
      "41744: loss=38.9647893906, acc=0.421875, epoch=6.61291089109\n",
      "41760: loss=38.6218941212, acc=0.3984375, epoch=6.61544554455\n",
      "41776: loss=41.777534008, acc=0.36328125, epoch=6.61798019802\n",
      "41792: loss=41.5798736811, acc=0.36328125, epoch=6.62051485149\n",
      "41808: loss=42.8858587742, acc=0.40234375, epoch=6.62304950495\n",
      "41824: loss=40.5842975378, acc=0.37109375, epoch=6.62558415842\n",
      "41840: loss=40.5087611675, acc=0.375, epoch=6.62811881188\n",
      "41856: loss=44.1224969625, acc=0.37109375, epoch=6.63065346535\n",
      "41872: loss=38.3822004795, acc=0.421875, epoch=6.63318811881\n",
      "41888: loss=39.4541926384, acc=0.421875, epoch=6.63572277228\n",
      "41904: loss=42.0165487528, acc=0.34375, epoch=6.63825742574\n",
      "41920: loss=38.977955699, acc=0.40625, epoch=6.64079207921\n",
      "41936: loss=41.955653429, acc=0.3359375, epoch=6.64332673267\n",
      "41952: loss=36.7592353821, acc=0.40234375, epoch=6.64586138614\n",
      "41968: loss=41.9086127281, acc=0.33984375, epoch=6.6483960396\n",
      "41984: loss=42.4700242281, acc=0.359375, epoch=6.65093069307\n",
      "42000: loss=42.6452996731, acc=0.3515625, epoch=6.65346534653\n",
      "42016: loss=41.6128356457, acc=0.3828125, epoch=6.656\n",
      "42032: loss=41.6702041626, acc=0.35546875, epoch=6.65853465347\n",
      "42048: loss=42.986423254, acc=0.32421875, epoch=6.66106930693\n",
      "42064: loss=40.3886988163, acc=0.375, epoch=6.6636039604\n",
      "42080: loss=44.6121768951, acc=0.328125, epoch=6.66613861386\n",
      "42096: loss=43.5337772369, acc=0.3359375, epoch=6.66867326733\n",
      "42112: loss=39.0458595753, acc=0.359375, epoch=6.67120792079\n",
      "42128: loss=41.7754733562, acc=0.37890625, epoch=6.67374257426\n",
      "42144: loss=39.5233938694, acc=0.37890625, epoch=6.67627722772\n",
      "42160: loss=41.3423439264, acc=0.359375, epoch=6.67881188119\n",
      "42176: loss=42.2914032936, acc=0.37109375, epoch=6.68134653465\n",
      "42192: loss=42.2536764145, acc=0.3359375, epoch=6.68388118812\n",
      "42208: loss=38.9554578066, acc=0.3828125, epoch=6.68641584158\n",
      "42224: loss=39.4934030771, acc=0.37890625, epoch=6.68895049505\n",
      "42240: loss=42.2284152508, acc=0.359375, epoch=6.69148514851\n",
      "42256: loss=39.5692617893, acc=0.4375, epoch=6.69401980198\n",
      "42272: loss=39.3769390583, acc=0.390625, epoch=6.69655445545\n",
      "42288: loss=42.2324324846, acc=0.3671875, epoch=6.69908910891\n",
      "42304: loss=41.4180423021, acc=0.3515625, epoch=6.70162376238\n",
      "42320: loss=37.7534784079, acc=0.421875, epoch=6.70415841584\n",
      "42336: loss=43.0702275038, acc=0.39453125, epoch=6.70669306931\n",
      "42352: loss=43.0762782097, acc=0.359375, epoch=6.70922772277\n",
      "42368: loss=41.9158681631, acc=0.375, epoch=6.71176237624\n",
      "42384: loss=40.7260648012, acc=0.37890625, epoch=6.7142970297\n",
      "42400: loss=40.1702691317, acc=0.40625, epoch=6.71683168317\n",
      "42416: loss=40.0534110069, acc=0.375, epoch=6.71936633663\n",
      "42432: loss=41.5978677273, acc=0.37109375, epoch=6.7219009901\n",
      "42448: loss=40.6089850664, acc=0.34765625, epoch=6.72443564356\n",
      "42464: loss=39.1627229452, acc=0.40234375, epoch=6.72697029703\n",
      "42480: loss=39.1678705215, acc=0.390625, epoch=6.7295049505\n",
      "42496: loss=42.0642056465, acc=0.35546875, epoch=6.73203960396\n",
      "42512: loss=38.3022047281, acc=0.40234375, epoch=6.73457425743\n",
      "42528: loss=44.2651462555, acc=0.34375, epoch=6.73710891089\n",
      "42544: loss=41.578858614, acc=0.3515625, epoch=6.73964356436\n",
      "42560: loss=43.757860899, acc=0.33984375, epoch=6.74217821782\n",
      "42576: loss=42.018941164, acc=0.35546875, epoch=6.74471287129\n",
      "42592: loss=38.9049344063, acc=0.40234375, epoch=6.74724752475\n",
      "42608: loss=41.8371690512, acc=0.35546875, epoch=6.74978217822\n",
      "42624: loss=39.560210824, acc=0.34375, epoch=6.75231683168\n",
      "42640: loss=41.0684498549, acc=0.3671875, epoch=6.75485148515\n",
      "42656: loss=38.303178668, acc=0.39453125, epoch=6.75738613861\n",
      "42672: loss=40.5136742592, acc=0.34375, epoch=6.75992079208\n",
      "42688: loss=40.0093204975, acc=0.38671875, epoch=6.76245544554\n",
      "42704: loss=39.2173023224, acc=0.39453125, epoch=6.76499009901\n",
      "42720: loss=41.315728426, acc=0.41015625, epoch=6.76752475248\n",
      "42736: loss=39.0808495283, acc=0.37890625, epoch=6.77005940594\n",
      "42752: loss=40.3508585691, acc=0.375, epoch=6.77259405941\n",
      "42768: loss=40.4457064867, acc=0.37890625, epoch=6.77512871287\n",
      "42784: loss=41.6382852793, acc=0.375, epoch=6.77766336634\n",
      "42800: loss=39.2026346922, acc=0.37890625, epoch=6.7801980198\n",
      "42816: loss=39.2999693155, acc=0.41796875, epoch=6.78273267327\n",
      "42832: loss=40.4640432596, acc=0.37109375, epoch=6.78526732673\n",
      "42848: loss=43.2806818485, acc=0.3515625, epoch=6.7878019802\n",
      "42864: loss=38.990093112, acc=0.3828125, epoch=6.79033663366\n"
     ]
    }
   ],
   "source": [
    "sv = tf.train.Supervisor(logdir='models/foodnetwork-10-3', save_model_secs=60 * 5)\n",
    "\n",
    "if MODE == 'train':\n",
    "\n",
    "    chart = charttt.Board('foodnetwork').chart('foodnetwork 10-3 (64x64 input)')\n",
    "\n",
    "    with sv.managed_session() as sess:\n",
    "\n",
    "        # init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        # sess.run(init_op)\n",
    "        tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "        losses = []\n",
    "        accs = []\n",
    "\n",
    "        while not sv.should_stop():\n",
    "            step = sess.run(n.global_step)\n",
    "            images, filenames = sess.run([images_batch, filenames_batch])\n",
    "            label_strings = [paths_to_labels[path] for path in filenames]\n",
    "            label_indices = [labels.index(label) for label in label_strings]\n",
    "\n",
    "            epoch = step * BATCH_SIZE * 1.0 / len(paths_to_labels)\n",
    "            lr = 0.0001\n",
    "\n",
    "            _, loss, acc = sess.run([n.train_op, n.loss, n.accuracy], feed_dict={\n",
    "                n.lr: lr,\n",
    "                n.inputs: images,\n",
    "                n.labels: label_indices,\n",
    "                n.dropout: 0.5\n",
    "            })\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "            # print logits[0]\n",
    "            if step % 16 == 0:\n",
    "                chart.write(epoch, loss=avg(losses), accuracy=avg(accs))\n",
    "                print \"{}: loss={}, acc={}, epoch={}\".format(step, avg(losses), avg(accs), epoch)\n",
    "                losses = []\n",
    "                accs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a directory of 1000 random images:\n",
    "\n",
    "def create_null_dir():\n",
    "\n",
    "    import shutil\n",
    "\n",
    "    print nulldir\n",
    "\n",
    "    def iterate_images_recursively(path, extensions=['.jpeg', '.jpg', '.png', '.gif']):\n",
    "        def is_image(path):\n",
    "            for ext in extensions:\n",
    "                if path.lower().endswith(ext):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        for (dirpath, dirname, filenames) in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                subpath = os.path.join(dirpath, filename)\n",
    "                if is_image(subpath):\n",
    "                    yield subpath\n",
    "\n",
    "    tiny_imagenet_images = list(iterate_images_recursively('../data/tiny-imagenet-200/train'))\n",
    "    floor_images = list(iterate_images_recursively('../data/floors'))\n",
    "\n",
    "    nulldir = os.path.join(root, 'null')\n",
    "    try:\n",
    "        os.rmdir(nulldir)\n",
    "    except OSError:\n",
    "        pass\n",
    "    os.mkdir(nulldir)\n",
    "\n",
    "    for i in xrange(1000):\n",
    "        path = random.choice(random.choice([tiny_imagenet_images, floor_images]))\n",
    "        ext = path.split('.')[-1]\n",
    "        name = os.path.join(nulldir, '{}.{}'.format(i, ext))\n",
    "        shutil.copyfile(path, name)\n",
    "\n",
    "# create_null_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODE == 'eval':\n",
    "\n",
    "    def softmax(x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    \n",
    "    def try_image(url):\n",
    "        \n",
    "        with sv.managed_session() as sess:\n",
    "\n",
    "            img = io.imread(url)\n",
    "            img = resize(img, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "            img = np.expand_dims(img, 0)\n",
    "            print img.shape\n",
    "\n",
    "            feed = {\n",
    "                n.dropout: 1,\n",
    "                n.inputs: img\n",
    "            }\n",
    "            predictions = softmax(sess.run(n.logits, feed_dict=feed)[0])\n",
    "            indices = sorted(range(102), key=lambda i: predictions[i], reverse=True)\n",
    "            for i in indices:\n",
    "                print labels[i], ':', predictions[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waffles = 'http://3.bp.blogspot.com/-agOrGBzjpKw/UHMB77A5NnI/AAAAAAAAD0Q/wOL7KXEh1-Y/s1600/DSC_0422.JPG'\n",
    "dumplings = 'http://i.ndtvimg.com/i/2015-01/dumplings_625x350_81421835686.jpg'\n",
    "hotdog = 'http://www.hot-dog.org/themes/bootstrap/hotdog/images/regional-hot-dog-California.jpg'\n",
    "grilledcheese = 'https://img.wonderhowto.com/img/23/72/63535591202690/0/make-lazy-grilled-cheese-sandwiches-your-toaster.w1456.jpg'\n",
    "\n",
    "try_image(grilledcheese)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
